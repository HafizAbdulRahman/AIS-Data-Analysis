{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305c0b58-25fe-4a14-9a93-91f661516d61",
   "metadata": {},
   "source": [
    "# Filtering the raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b62233-656b-48e8-8fa8-cfba767730cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: aisdk-2025-01-25.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herox\\AppData\\Local\\Temp\\ipykernel_15008\\3779526722.py:9: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(file_path, parse_dates=['# Timestamp'])  # Ensure '# Timestamp' is recognized as datetime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Total rows: 17422586\n",
      "Filtering data...\n",
      "Applying two-minute time gap filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herox\\AppData\\Local\\Temp\\ipykernel_15008\\3779526722.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('MMSI', group_keys=False).apply(filter_two_minutes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering complete. Remaining rows: 76337\n",
      "Saving the filtered data to: aisdk-2025-01-25_filtered.csv...\n",
      "Filtered data saved successfully: aisdk-2025-01-25_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the input and output file paths\n",
    "file_path = \"aisdk-2025-01-25.csv\"  # Replace with your actual file path\n",
    "output_file_path = file_path.replace(\".csv\", \"_filtered.csv\")\n",
    "\n",
    "# Step 2: Load the CSV file\n",
    "print(f\"Loading data from: {file_path}...\")\n",
    "df = pd.read_csv(file_path, parse_dates=['# Timestamp'])  # Ensure '# Timestamp' is recognized as datetime\n",
    "print(f\"Data loaded successfully. Total rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894c253-5ed7-49d5-914f-ddd8c702903a",
   "metadata": {},
   "source": [
    "# Filteration Critera\n",
    "1) Remove the rows having Longitude = 0\n",
    "2) Keep only Ship type Cargo, Tanker and if Unknown then check length and if it is greater then 100 then include in data.\n",
    "3) Remove duplicate rows\n",
    "4) For each MMSI/vessel, take only 1 record in two minutes time interverl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c673d-7cbc-4114-a09c-4e39e8188350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter the data\n",
    "print(\"Filtering data...\")\n",
    "# Remove rows where 'Longitude' is 0\n",
    "df = df[df['Longitude'] != 0]\n",
    "\n",
    "# Keep rows where 'Ship type' is 'Cargo', 'Tanker', or 'Undefined' (if Length > 100)\n",
    "df = df[\n",
    "    (df['Ship type'].isin(['Cargo', 'Tanker'])) |\n",
    "    ((df['Ship type'] == 'Undefined') & (df['Length'] > 100))\n",
    "]\n",
    "\n",
    "# Remove duplicate rows based on 'IMO' and '# Timestamp'\n",
    "df = df.drop_duplicates(subset=['IMO', '# Timestamp'])\n",
    "\n",
    "# Sort by 'MMSI' and '# Timestamp' to prepare for time filtering\n",
    "df = df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "\n",
    "# Apply two-minute time gap filtration for each MMSI\n",
    "print(\"Applying two-minute time gap filtering...\")\n",
    "def filter_two_minutes(group):\n",
    "    group = group.sort_values(by='# Timestamp')\n",
    "    return group[group['# Timestamp'].diff().dt.total_seconds().fillna(120) >= 120]\n",
    "\n",
    "df = df.groupby('MMSI', group_keys=False).apply(filter_two_minutes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141162ab-9756-4fe2-8a5b-b2f5fbf393a3",
   "metadata": {},
   "source": [
    "# Remove the un-necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba366e7-7e4b-469b-8e93-8c1aaff1c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Width', 'Type of position fixing device', 'Data source type', \n",
    "    'A', 'B', 'C', 'D'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')  # Ignore errors if columns don't exist\n",
    "\n",
    "print(f\"Filtering complete. Remaining rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46bcc4-a0ca-4f05-9c4a-50f5e7294a4b",
   "metadata": {},
   "source": [
    "# Save the file after flteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5f82e-3657-4c4d-83d2-8dfd0a73e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save the filtered data\n",
    "print(f\"Saving the filtered data to: {output_file_path}...\")\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Filtered data saved successfully: {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
